# ğŸš€ OpsFleet - Professional ReAct Data Analysis Agent

> Intelligent data analysis agent with genius-level planning, BigQuery integration, and LangSmith tracing

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ğŸ¯ Overview

This is a production-ready **Professional ReAct Agent** that combines strategic planning, data sampling, and self-healing execution to deliver reliable data analysis results. Built with modern AI engineering best practices, it features genius-level multi-phase planning and comprehensive observability.

### Key Capabilities

- ğŸ§  **Genius-Level Planning** - Multi-phase strategic planning with data sampling
- ğŸ“Š **BigQuery Integration** - Smart SQL generation with schema awareness
- ğŸ” **LangSmith Tracing** - Full observability with thread support
- ğŸ”„ **Self-Healing Execution** - Automatic error recovery and validation
- ğŸ’¬ **Beautiful CLI** - Professional interface with real-time progress
- âš¡ **High Performance** - Cached schemas and optimized queries
- ğŸ¯ **Step-by-Step ReAct** - Think-Act-Observe execution cycle

## âœ¨ Features

### Core Features

- âœ… **Professional ReAct Agent** with 5-stage pipeline
- âœ… **Multi-Phase Planning** (Strategic Analysis â†’ Decomposition â†’ Optimization â†’ Validation)
- âœ… **Data Sampling** - Understands actual data formats before SQL generation
- âœ… **Smart SQL Generation** - BigQuery-specific with column validation
- âœ… **Self-Healing** - Automatic retry with error analysis
- âœ… **Conversation History** - Context-aware multi-turn dialogues
- âœ… **Progress Tracking** - Real-time updates for each stage
- âœ… **Comprehensive Logging** - Structured logs with LangSmith integration

### Advanced Features

- ğŸ¯ **Strategic Analysis** - Understands real goals beyond surface queries
- ğŸ”¨ **Problem Decomposition** - Breaks complex tasks into atomic steps
- âš¡ **Execution Optimization** - Combines queries and parallelizes operations
- ğŸ›¡ï¸ **Risk Assessment** - Proactive problem identification
- ğŸ“ˆ **Confidence Scoring** - Success probability estimation
- ğŸ”„ **Cached Data Samples** - Reused across session for performance

## ğŸ“¸ Screenshots

### Beautiful CLI Interface

The OpsFleet agent features a modern, professional CLI with ASCII art branding and real-time progress tracking.

![OpsFleet CLI Welcome Screen](docs/screenshots/cli-welcome.png)
*Welcome screen with OPSFLEET ASCII art logo, features panel, and commands*

### Live Query Execution

Watch the agent work through its 5-stage pipeline with detailed progress updates.

![Query Execution Progress](docs/screenshots/query-execution.png)
*Real-time progress showing Understanding â†’ Planning â†’ Execution â†’ Validation â†’ Synthesis*

### Execution Details

See the complete execution plan with step-by-step breakdown and results.

![Execution Details](docs/screenshots/execution-details.png)
*Detailed execution plan showing actions, thoughts, and outputs*

### Data Results

Beautiful table rendering with summary statistics for quick insights.

![Data Results](docs/screenshots/data-results.png)
*Query results with formatted tables and summary statistics*

### Multi-Stage Pipeline

Visual representation of the agent's thinking process through each stage.

![Pipeline Stages](docs/screenshots/pipeline-stages.png)
*5-stage pipeline: Database â†’ Understanding â†’ Planning â†’ Execution â†’ Validation â†’ Interpretation â†’ Synthesis*

## ğŸ—ï¸ Architecture

### System Overview

```mermaid
graph TB
    User[ğŸ‘¤ User] -->|Query| CLI[ğŸ–¥ï¸ CLI Interface]
    CLI -->|Process| Agent[ğŸ¤– Professional ReAct Agent]
    
    Agent -->|Stage 1| Understanding[ğŸ§  Understanding]
    Agent -->|Stage 2| Planning[ğŸ“‹ Genius Planning]
    Agent -->|Stage 3| Execution[âš¡ ReAct Execution]
    Agent -->|Stage 4| Validation[âœ… Validation]
    Agent -->|Stage 5| Synthesis[ğŸ“ Synthesis]
    
    Planning -->|Sample Data| BQ[(BigQuery)]
    Execution -->|Execute SQL| BQ
    
    Agent -->|Trace| LangSmith[ğŸ“Š LangSmith]
    Agent -->|Cache| Memory[ğŸ’¾ Cache]
    
    style Agent fill:#4CAF50
    style Planning fill:#2196F3
    style Execution fill:#FF9800
    style BQ fill:#4285F4
```

### 5-Stage Pipeline

```mermaid
sequenceDiagram
    participant U as User
    participant A as Agent
    participant P as Planner
    participant E as Executor
    participant BQ as BigQuery
    participant L as LangSmith
    
    U->>A: "Show January sales"
    
    Note over A: Stage 1: Understanding
    A->>A: Analyze intent
    A->>L: Log understanding
    
    Note over A,P: Stage 2: Genius Planning
    A->>P: Create strategic plan
    P->>BQ: Sample data (3 rows/table)
    BQ-->>P: Sample data + types
    P->>P: Strategic Analysis
    P->>P: Problem Decomposition
    P->>P: Execution Optimization
    P->>P: Validation
    P-->>A: Optimized plan
    A->>L: Log plan
    
    Note over A,E: Stage 3: ReAct Execution
    loop For each step
        E->>E: Think (analyze step)
        E->>BQ: Act (execute SQL)
        BQ-->>E: Results
        E->>E: Observe (validate)
        E->>L: Log step
    end
    E-->>A: Execution results
    
    Note over A: Stage 4: Validation
    A->>A: Validate results
    A->>L: Log validation
    
    Note over A: Stage 5: Synthesis
    A->>A: Generate insights
    A->>L: Log synthesis
    A-->>U: Beautiful report
```

### Multi-Phase Planning Architecture

```mermaid
graph LR
    Query[User Query] --> Phase0[Phase 0:<br/>Data Sampling]
    
    Phase0 --> Sample1[Sample orders<br/>3 rows]
    Phase0 --> Sample2[Sample products<br/>3 rows]
    Phase0 --> Sample3[Sample users<br/>3 rows]
    
    Sample1 --> Types[Infer Types:<br/>created_at=TIMESTAMP<br/>order_id=INTEGER]
    Sample2 --> Types
    Sample3 --> Types
    
    Types --> Phase1[Phase 1:<br/>Strategic Analysis]
    
    Phase1 --> Goal[Ultimate Goal]
    Phase1 --> Tables[Tables Needed]
    Phase1 --> Risks[Risk Assessment]
    
    Phase1 --> Phase2[Phase 2:<br/>Problem Decomposition]
    
    Phase2 --> Atomic[Atomic Steps]
    Phase2 --> Deps[Dependencies]
    Phase2 --> Critical[Critical Path]
    
    Phase2 --> Phase3[Phase 3:<br/>Execution Optimization]
    
    Phase3 --> Combine[Combine Queries]
    Phase3 --> Parallel[Parallelize]
    Phase3 --> Minimize[Minimize Data]
    
    Phase3 --> Phase4[Phase 4:<br/>Validation]
    
    Phase4 --> Check[Completeness Check]
    Phase4 --> Confidence[Confidence Score]
    Phase4 --> Success[Success Probability]
    
    Phase4 --> Plan[Optimized<br/>Execution Plan]
    
    style Phase0 fill:#E3F2FD
    style Phase1 fill:#FFF3E0
    style Phase2 fill:#F3E5F5
    style Phase3 fill:#E8F5E9
    style Phase4 fill:#FCE4EC
    style Plan fill:#4CAF50
```

### Component Architecture

```mermaid
graph TB
    subgraph "CLI Layer"
        CLI[cli_chat.py]
        Display[Beautiful Display]
    end
    
    subgraph "Agent Layer"
        PRA[ProfessionalReActAgent]
        GP[Genius Planner]
        Memory[Conversation Memory]
    end
    
    subgraph "Orchestration Layer"
        Tools[Tools Module]
        BQTool[BigQuery Tool]
        AnalyzeTool[Analyze Tool]
        ReportTool[Report Tool]
    end
    
    subgraph "Data Layer"
        Cache[Schema Cache]
        Samples[Data Samples]
        History[Conversation History]
    end
    
    subgraph "External Services"
        BQ[(BigQuery)]
        LLM[LLM Provider<br/>Gemini/Ollama]
        LS[LangSmith]
    end
    
    CLI --> PRA
    Display --> CLI
    
    PRA --> GP
    PRA --> Memory
    PRA --> Tools
    
    GP --> Samples
    Tools --> BQTool
    Tools --> AnalyzeTool
    Tools --> ReportTool
    
    BQTool --> BQ
    PRA --> Cache
    PRA --> History
    
    PRA --> LLM
    PRA --> LS
    
    style PRA fill:#4CAF50
    style GP fill:#2196F3
    style BQ fill:#4285F4
    style LS fill:#FF9800
```

### Data Flow

```mermaid
flowchart TD
    Start([User Query]) --> Cache{Schema<br/>Cached?}
    
    Cache -->|No| Explore[Explore Schema]
    Cache -->|Yes| Sample[Sample Data]
    
    Explore --> Store[Store Schema]
    Store --> Sample
    
    Sample --> Infer[Infer Data Types]
    Infer --> Strategic[Strategic Analysis]
    
    Strategic --> Decompose[Problem Decomposition]
    Decompose --> Optimize[Optimize Execution]
    Optimize --> Validate[Validate Plan]
    
    Validate --> Execute[Execute Steps]
    
    Execute --> Think[Think]
    Think --> Act[Act]
    Act --> Observe[Observe]
    
    Observe --> More{More<br/>Steps?}
    More -->|Yes| Think
    More -->|No| Results[Collect Results]
    
    Results --> ValidateR[Validate Results]
    ValidateR --> Pass{Valid?}
    
    Pass -->|No| Retry{Retry<br/>Count?}
    Retry -->|< 3| Fix[Fix & Retry]
    Fix --> Execute
    Retry -->|>= 3| Error[Return Error]
    
    Pass -->|Yes| Synthesize[Synthesize Insights]
    Synthesize --> Report[Generate Report]
    Report --> End([Return to User])
    
    style Start fill:#4CAF50
    style End fill:#4CAF50
    style Execute fill:#2196F3
    style Report fill:#FF9800
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Google Cloud account with BigQuery access
- LangSmith API key (optional, for tracing)
- Gemini API key or Ollama installed

### Installation

1. **Clone the repository**:
```bash
git clone https://github.com/vladykart/opsfleet.git
cd opsfleet
```

2. **Install dependencies**:
```bash
pip install -r requirements.txt
```

3. **Configure environment**:
```bash
cp .env.example .env
# Edit .env with your credentials:
# - GOOGLE_APPLICATION_CREDENTIALS
# - LANGSMITH_API_KEY
# - GEMINI_API_KEY (or use Ollama)
```

4. **Run the agent**:
```bash
python cli_chat.py --verbose
```

### First Query

```bash
You: Show orders from January 2024

â ‹ Db_Exploration: Exploring schema...
âœ“ Db_Exploration: Cached 4 tables
â ‹ Understanding: Analyzing intent...
âœ“ Understanding: retrieve January 2024 orders
â ‹ Planning: Sampling data...
â ‹ Planning: Strategic analysis...
â ‹ Planning: Decomposing problem...
â ‹ Planning: Optimizing execution...
â ‹ Planning: Validating plan...
âœ“ Planning: 1 step(s) - confidence: 0.95
â ‹ Execution: Step 1/1: Thinking...
â ‹ Execution: Step 1/1: Executing bigquery...
âœ“ Execution: 1 completed
âœ“ Validation: Confidence: 95%
âœ“ Synthesis: Done

ğŸ“Š Results displayed with insights and recommendations
```

## ğŸ“ Project Structure

```
opsfleet/
â”œâ”€â”€ ğŸ“„ cli_chat.py                    # Main CLI interface
â”œâ”€â”€ ğŸ“„ README.md                      # This file
â”œâ”€â”€ ğŸ“„ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ“„ .env.example                   # Environment template
â”‚
â”œâ”€â”€ ğŸ“ src/                           # Source code
â”‚   â”œâ”€â”€ ğŸ“ agents/                    # Agent implementations
â”‚   â”‚   â”œâ”€â”€ professional_react_agent.py   # Main ReAct agent
â”‚   â”‚   â”œâ”€â”€ genius_planner.py            # Multi-phase planner (deprecated, integrated)
â”‚   â”‚   â””â”€â”€ enhanced_base_agent.py       # Base agent class
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ orchestration/             # Orchestration layer
â”‚   â”‚   â”œâ”€â”€ tools.py                     # Tool definitions (BigQuery, Analyze, Report)
â”‚   â”‚   â”œâ”€â”€ task_orchestrator.py         # Task coordination
â”‚   â”‚   â””â”€â”€ react_agent.py               # ReAct pattern implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ cache/                     # Caching layer
â”‚   â”‚   â”œâ”€â”€ conversation_cache.py        # Query result caching
â”‚   â”‚   â””â”€â”€ history_db.py                # Conversation history storage
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ model_router.py            # LLM provider routing
â”‚   â””â”€â”€ ğŸ“„ prompts_library.py         # Prompt templates
â”‚
â”œâ”€â”€ ğŸ“ tests/                         # Test suite
â”‚   â”œâ”€â”€ test_connections.py              # Connection tests
â”‚   â”œâ”€â”€ test_integration.py              # Integration tests
â”‚   â”œâ”€â”€ test_langsmith.py                # LangSmith tracing tests
â”‚   â””â”€â”€ test_quick.py                    # Quick smoke tests
â”‚
â”œâ”€â”€ ğŸ“ docs/                          # Documentation (57 files)
â”‚   â”œâ”€â”€ QUICKSTART.md                    # Quick start guide
â”‚   â”œâ”€â”€ GENIUS_PLANNER.md                # Planning architecture
â”‚   â”œâ”€â”€ REACT_STEP_BY_STEP.md            # ReAct execution guide
â”‚   â”œâ”€â”€ LANGSMITH_THREADS_IMPLEMENTATION.md  # Tracing setup
â”‚   â”œâ”€â”€ SCHEMA_AWARE_SQL_GENERATION.md   # SQL generation guide
â”‚   â””â”€â”€ ... (50+ more documentation files)
â”‚
â”œâ”€â”€ ğŸ“ config/                        # Configuration
â”‚   â””â”€â”€ mcp_config.json                  # MCP server configuration
â”‚
â”œâ”€â”€ ğŸ“ utils/                         # Utilities
â”‚   â”œâ”€â”€ logging_utils.py                 # Logging helpers
â”‚   â””â”€â”€ validation_utils.py              # Validation helpers
â”‚
â””â”€â”€ ğŸ“ examples/                      # Example scripts
    â””â”€â”€ model_router_example.py          # Model routing examples
```

### Key Files

| File | Purpose |
|------|---------|
| `cli_chat.py` | Main entry point - Beautiful CLI interface |
| `src/agents/professional_react_agent.py` | Core agent with 5-stage pipeline |
| `src/orchestration/tools.py` | Tool implementations (BigQuery, Analyze, Report) |
| `src/cache/conversation_cache.py` | Query result caching for performance |
| `src/model_router.py` | Multi-LLM provider support |

## ğŸ“š Documentation

### Getting Started
- ğŸ“– [Quick Start Guide](docs/QUICKSTART.md) - Get running in 5 minutes
- ğŸ“– [CLI Guide](docs/QUICKSTART_CLI.md) - CLI usage and features
- ğŸ“– [Setup Checklist](docs/SETUP_CHECKLIST.md) - Complete setup guide

### Architecture & Design
- ğŸ—ï¸ [Genius Planner](docs/GENIUS_PLANNER.md) - Multi-phase planning architecture
- ğŸ—ï¸ [ReAct Step-by-Step](docs/REACT_STEP_BY_STEP.md) - ReAct execution pattern
- ğŸ—ï¸ [Agent Patterns](docs/AGENT_PATTERNS.md) - Design patterns used
- ğŸ—ï¸ [Model Router](docs/MODEL_ROUTER.md) - LLM provider routing

### Features
- âœ¨ [Schema-Aware SQL](docs/SCHEMA_AWARE_SQL_GENERATION.md) - Smart SQL generation
- âœ¨ [Self-Healing Execution](docs/SELF_HEALING_EXECUTION.md) - Automatic error recovery
- âœ¨ [Data Caching](docs/DATA_CACHING.md) - Performance optimization
- âœ¨ [LangSmith Integration](docs/LANGSMITH_THREADS_IMPLEMENTATION.md) - Observability

### Development
- ğŸ”§ [Contributing Guide](docs/CONTRIBUTING.md) - How to contribute
- ğŸ”§ [Testing Guide](docs/TESTING_COMPLETE.md) - Running tests
- ğŸ”§ [Project Status](docs/PROJECT_STATUS.md) - Current status

## ğŸ¯ Usage Examples

### Basic Query
```python
from src.agents.professional_react_agent import ProfessionalReActAgent

agent = ProfessionalReActAgent(config={
    "llm_provider": "gemini",
    "enable_db_exploration": True
})

result = await agent.process("Show top 10 products by revenue")
print(result['response'])
```

### With Progress Tracking
```python
def progress_callback(stage, status, message):
    print(f"[{stage}] {status}: {message}")

agent.progress_callback = progress_callback
result = await agent.process("Analyze January sales trends")
```

### CLI Usage
```bash
# Interactive mode
python cli_chat.py --verbose

# Single query
python cli_chat.py --query "Show orders from January"

# With specific LLM
python cli_chat.py --model ollama --verbose
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run specific test
pytest tests/test_integration.py -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Quick smoke test
python tests/test_quick.py
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# Required
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# Optional - LangSmith Tracing
LANGSMITH_API_KEY=your_key_here
LANGSMITH_TRACING=true
LANGSMITH_PROJECT=opsfleet

# Optional - LLM Providers
GEMINI_API_KEY=your_gemini_key
OPENAI_API_KEY=your_openai_key

# Optional - BigQuery
BIGQUERY_PROJECT_ID=your-project-id
BIGQUERY_DATASET=thelook_ecommerce
```

### LLM Providers

OpsFleet supports multiple LLM providers:

| Provider | Setup | Use Case |
|----------|-------|----------|
| **Gemini** | Set `GEMINI_API_KEY` | Production, fast responses |
| **Ollama** | Install Ollama locally | Development, privacy |
| **OpenAI** | Set `OPENAI_API_KEY` | Alternative cloud option |

## ğŸš€ Deployment

### Docker (Coming Soon)
```bash
docker build -t opsfleet .
docker run -p 8000:8000 opsfleet
```

### Cloud Run (Coming Soon)
```bash
gcloud run deploy opsfleet \
  --source . \
  --region us-central1 \
  --allow-unauthenticated
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](docs/CONTRIBUTING.md).

### Development Setup

```bash
# Clone and install
git clone https://github.com/vladykart/opsfleet.git
cd opsfleet
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Format code
black src/ tests/
isort src/ tests/

# Lint
pylint src/
```

## ğŸ“Š Performance

- **Query Latency**: 2-5 seconds (cached schema)
- **Planning Time**: 1-3 seconds (with data sampling)
- **Execution Time**: Depends on query complexity
- **Success Rate**: 90%+ with self-healing
- **Cache Hit Rate**: 80%+ for repeated queries

## ğŸ›£ï¸ Roadmap

- [ ] **API Server** - REST API for programmatic access
- [ ] **Web UI** - Browser-based interface
- [ ] **More Data Sources** - PostgreSQL, MySQL, Snowflake
- [ ] **Advanced Analytics** - ML-powered insights
- [ ] **Multi-Agent Collaboration** - Specialized agent teams
- [ ] **Streaming Responses** - Real-time result streaming

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details

## ğŸ™ Acknowledgments

- **LangSmith** - Observability and tracing
- **Google BigQuery** - Data warehouse
- **Google Gemini** - LLM provider
- **Ollama** - Local LLM support
- **ReAct Pattern** - Reasoning and acting framework

## ğŸ“§ Contact

- **GitHub**: [@vladykart](https://github.com/vladykart)
- **Repository**: [opsfleet](https://github.com/vladykart/opsfleet)
- **Issues**: [GitHub Issues](https://github.com/vladykart/opsfleet/issues)

---

**Built with â¤ï¸ by AI Engineer, for AI Engineers**
